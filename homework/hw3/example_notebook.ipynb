{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the documents we want to load, you will want to study \n",
    "\n",
    "* [`from sklearn.feature_extraction.text import TfidfVectorizer`]()\n",
    "* [`from sklearn.naive_bayes import MultinomialNB`]()\n",
    "\n",
    "Our test data will be given by the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map = {\n",
    "    'a': # Plato\n",
    "        [\n",
    "        'data/plato/test/pg1726.txt', # Title: Cratylus\n",
    "        'data/plato/test/pg1616.txt', # Title: Ion\n",
    "        'data/plato/test/pg1735.txt', # Title: Theaetetus \n",
    "        'data/plato/test/pg1635.txt'  # Title: Sophist\n",
    "        ],\n",
    "    'b': \n",
    "        [ # Hume\n",
    "        'data/hume/test/pg59792-0.txt', # Title: Hume's Political Discourses\n",
    "        'data/hume/test/pg62856-0.txt', # Title: A Treatise of Human Nature Being an Attempt to Introduce the Experimental Method into Moral Subjects\n",
    "        'data/hume/test/pg9662.txt',    # Title: An Enquiry Concerning Human Understanding\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/test/pg59058.txt', # Title: Aristotle's History of Animals In Ten Books\n",
    "        'data/aristotle/test/pg2412.txt',  # Title: The Categories\n",
    "        'data/aristotle/test/pg6762.txt',  # Title: Politics A Treatise on Government\n",
    "        'data/aristotle/test/pg1974.txt',  # Title: Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_map = {\n",
    "    'a': \n",
    "        [ # Plato\n",
    "        'data/plato/train/pg1750.txt', # Laws\n",
    "        'data/plato/train/pg1497.txt', # The Republic\n",
    "        'data/plato/train/pg1600.txt', # Symposium\n",
    "        ],\n",
    "    'b':\n",
    "        [ # Hume\n",
    "        'data/hume/train/pg10574.txt', # The History of England, Volume I\n",
    "        'data/hume/train/pg4705.txt',  # A Treatise of Human Nature\n",
    "        'data/hume/train/pg36120.txt', # Essays\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/train/pg8438.txt', # Ethics\n",
    "        'data/aristotle/train/pg26095.txt',# The Athenian Constitution\n",
    "        'data/aristotle/train/pg6763.txt'  # The Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = []\n",
    "y_train = []\n",
    "\n",
    "for k in training_map.keys():\n",
    "    files_train.extend(training_map[k])\n",
    "    y_train.extend(k * len(training_map[k]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./plato/train/pg1750.txt',\n",
       " './plato/train/pg1497.txt',\n",
       " './plato/train/pg1600.txt',\n",
       " './hume/train/pg10574.txt',\n",
       " './hume/train/pg4705.txt',\n",
       " './hume/train/pg36120.txt',\n",
       " './aristotle/train/pg8438.txt',\n",
       " './aristotle/train/pg26095.txt',\n",
       " './aristotle/train/pg6763.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dictionary map in the variable\n",
    "          `training_map`. Your function will take the files (in the order they appear in\n",
    "          `training_map`) and pass the  data into the [`TfidfVectorizer`]() vectorizer.  You\n",
    "          will need to set the parameter to the constructor to `input='file'` and the\n",
    "          `stop_words` to `'english'` (e.g. initialize the vectorizer to `TfidfVectorizer(input='file', stop_words='english')`.\n",
    "\n",
    "* **You will just need to show the new function and the initialization of the vectorizer in this step.**  This will be one or two cells at most.\n",
    "* You will use `fit_transform()` with the parameter being a list of the training files objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_pt1_function(files_train):\n",
    "    vectorizer = TfidfVectorizer(input='file', stop_words='english')\n",
    "    \n",
    "    # call vectorizer.fit_transform on the list of FILE OBJECTS  \n",
    "    \n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example to get a list of file objects from our `files_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_io.TextIOWrapper name='./plato/train/pg1750.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./plato/train/pg1497.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./plato/train/pg1600.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./hume/train/pg10574.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./hume/train/pg4705.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./hume/train/pg36120.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./aristotle/train/pg8438.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./aristotle/train/pg26095.txt' mode='r' encoding='UTF-8'>,\n",
       " <_io.TextIOWrapper name='./aristotle/train/pg6763.txt' mode='r' encoding='UTF-8'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[open(f) for f in files_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need only use this in your `fit_transform()` call of your function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II\n",
    "\n",
    "Now that you have a vectorizer which effectively builds the data structure to hold the\n",
    "TF-IDF of all the words which appear for each document, you can move to the training\n",
    "phase for the Bayesian classifier.  Look in the sample notebook for guidance. You will take as\n",
    "input the vectorizer output (the documents vectorized by TF-IDF) and the corresponding\n",
    "classes (in the order they appear in the original dictionary map) and pass that into the [`MultinomialNB.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) method.\n",
    "\n",
    "* **Show the initialization of your `MultinomialNB()` classifier and the application of the `fit()` method.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize MultinomialNB (one line) (e.g. clf = ???)\n",
    "\n",
    "\n",
    "# e.g. clf.fit( with_the_approproate_parameters )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III\n",
    "\n",
    "Once you have the classifier, you will need to convert a test file using\n",
    "the vectorizer from part I.  Then you will execute the `predict()` \n",
    "method of your classifier.\n",
    "\n",
    "Assume `vectorizer` is your TF-IDF vectorizer from above and the `clf` your\n",
    "classifier from part II above, your code could be modeled after this:\n",
    "\n",
    "```python\n",
    "x_test = vectorizer.transform([open(\"data/aristotle/test/pg2412.txt\")])\n",
    "\n",
    "# should be class C!\n",
    "clf.predict(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_pt3_function (a_document_vectorized_test_document, a_classifier):\n",
    "    # pred = a_classifier.predict ( your_vectorized_test_document )\n",
    "    \n",
    "    return pred[0]  # the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test all the documents, your code might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_test = [\n",
    "   (\"data/philosopher_name/test/filename.txt\", 'a'), # the class should match the file (e.g. Hume is 'b') \n",
    "   # add all the remaining files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, cls_predict in files_test:\n",
    "    # x_test =  vectorizer.transform([open(f)])\n",
    "    \n",
    "    # pred = your_pt3_function()\n",
    "    \n",
    "    # print (f\"{f}: {cls_predict == pred}\")\n",
    "    \n",
    "    pass # remove"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
