<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
<h1 id="mcis6273-data-mining-prof.-maull-fall-2020-hw2">MCIS6273 Data Mining (Prof. Maull) / Fall 2020 / HW2</h1>
<p><strong>This assignment is worth up to 10 POINTS to your grade total if you complete it on time.</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Points <br/>Possible</th>
<th style="text-align: center;">Due Date</th>
<th style="text-align: center;">Time Commitment <br/>(estimated)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">10</td>
<td style="text-align: center;">Monday, November 9 @ Midnight</td>
<td style="text-align: center;"><em>up to</em> 20 hours</td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>GRADING:</strong> Grading will be aligned with the completeness of the objectives.</p></li>
<li><p><strong>INDEPENDENT WORK:</strong> Copying, cheating, plagiarism and academic dishonesty <em>are not tolerated</em> by University or course policy. Please see the syllabus for the full departmental and University statement on the academic code of honor.</p></li>
</ul>
<h2 id="objectives">OBJECTIVES</h2>
<ul>
<li><p>Perform unsupervised learning with nearest-neighbors classification and regression</p></li>
<li><p>Perform Bayesian text classification</p></li>
</ul>
<h2 id="what-to-turn-in">WHAT TO TURN IN</h2>
<p>You are being encouraged to turn the assignment in using the provided Jupyter Notebook. To do so, make a directory in your Lab environment called <code>homework/hwN</code>. Put all of your files in that directory. Then zip that directory, rename it with your name as the first part of the filename (e.g. <code>maull_hwN_files.zip</code>), then download it to your local machine, then upload the <code>.zip</code> to Blackboard.</p>
<p>If you do not know how to do this, please ask, or visit one of the many tutorials out there on the basics of using zip in Linux.</p>
<p>If you choose not to use the provided notebook, you will still need to turn in a <code>.ipynb</code> Jupyter Notebook and corresponding files according to the instructions in this homework.</p>
<h2 id="assignment-tasks">ASSIGNMENT TASKS</h2>
<h3 id="perform-unsupervised-learning-with-nearest-neighbors-classification-and-regression">(50%) Perform unsupervised learning with nearest-neighbors classification and regression</h3>
<p>In the last homework we work with the diamonds dataset and learned a lot about how to understand and visualize some of the features of the data.</p>
<p>We also learned that maybe the price of diamonds is only partially due to the rated characteristics of the diamond. There ar surely more that meets the eye when pricing diamonds and there are qualitative as well as quantitative measures which factor into the price of a diamond.</p>
<p>We’re going to continue with this dataset on two routes. We’re first going to build a classicification model based on the nearest neighbors in the data. That is to say, given an arbitrary unseen diamond, we would like to have a model trained from the actual data which gives us a class label for that diamond.</p>
<p>For the sake of the exercise, we’re going to choose 5 labels for the diamonds all based on price. Instead of arbitrary cuts on those labels, we’re going to use the 2015 US Federal income tax brackets as our guide.</p>
<p>If you look at the brackets, there are distinct cutoffs which could serve as bins for our class labels. We don’t care necessarily what the labels are called, so we will just use letters ‘A’, ‘B’, ‘C’ and so on.</p>
<p>Once we have obtained the labels (and assigned them), we will then use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"><code>sklearn.neighbors.KNeighborsClassifier</code></a> to develop a model for classifying the data. Remember from our lectures we need to split the data into test, training/validation and a <em>holdout</em> set. The training set will be used to train the model, while the test set will be used to test the model. The holdout set will be our “unseen” data upon which real classification decisions will be made. We can evaluation the fitness of the final model on the holdout set and (hopefully) gain confidence that the model will do well in the real world.</p>
<p>§ Create labels for the data based on the first 5 tax brackets from the 2015 US Federal Income brackets. You only need to consider the <em>Single</em> 10%, 15%, 25%, 28% and 33% brackets which ends at $411,500. <strong>Do not use the married or head of household brackets</strong>. The full bracket information can be found here: <a href="https://www.bankrate.com/finance/taxes/2015-tax-bracket-rates.aspx">https://www.bankrate.com/finance/taxes/2015-tax-bracket-rates.aspx</a>.</p>
<ol type="1">
<li><p>For each bracket compute a value <span class="math inline"><em>φ</em></span> which is 10% of half the difference between the top and bottom of the bracket. For example, <span class="math display">$$\varphi_c = \frac{b_{max} - b_{min}}{2} \times 0.10$$</span>.</p>
<p>So if the top of a bracket <span class="math inline"><em>b</em><sub><em>m</em><em>a</em><em>x</em></sub> = 5000</span> and the bottom of the bracket <span class="math inline"><em>b</em><sub><em>m</em><em>i</em><em>n</em></sub> = 2500</span>, then <span class="math inline"><em>φ</em> = 125</span>. This number will represent the cutoff of the class, so that the range for the class extends from the previous class to the current one just calculated. The classes will ultimately look like this <span class="math inline"><em>C</em><sub>1</sub> = [0, <em>φ</em><sub><em>c</em><sub>1</sub></sub>], <em>C</em><sub>2</sub> = (<em>φ</em><sub><em>c</em><sub>1</sub></sub>, <em>φ</em><sub><em>c</em><sub>2</sub></sub>], …, <em>C</em><sub><em>n</em></sub> = (<em>φ</em><sub><em>c</em><sub><em>n</em> − 1</sub></sub>, <em>φ</em><sub><em>c</em><sub><em>n</em></sub></sub>]</span>.</p></li>
<li><p>Now label the original data from your diamonds data with the labels ‘A’ … ‘E’ where ‘A’ is the first class, ‘B’, the second and so on. You will need to create a function that checks the class ranges for the price and applies that function accordingly to produce a new feature <code>class</code>. You can do this very simply with the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html"><code>apply</code></a> function.</p></li>
<li><p>Store the labeled data (the new DataFrame with the class) into a file for all rows.</p></li>
</ol>
<p>§ Now that we have the dataset, let’s create a training and test set and beging model building. The easiest way to create your holdout set is to take a random sample of 25% of the data and use that as the holdout. You can can take the remaining 75% of the data and use it for the test/train split. While there are not steadfast rules for how much data you should use to train, test and validate with, a good rule of thumb is to train on no less than 20% of the data, if possible, and validate on between 20-25% of the data. If you have a large enough dataset (millions of instances), you may be able to train on 10% of the data. Of course, your choice of classifier may also help guide the decision on splitting data.</p>
<ol type="1">
<li><p>Create a 25% validation set and use the remaining data to do a 30%/70% test/train split. We have enough instances to create a dataset that should yield good accuracy. The <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"><code>sklearn.model_selection.train_test_split()</code></a> is a great place to start and will save you a great deal of time.</p></li>
<li><p>Store the data into 3 files <code>test.csv</code>, <code>train.csv</code> and <code>validate.csv</code>.</p></li>
</ol>
<p>§ Now that we have data that we need, we can perform the classification task we originally wanted. Recall, the goal is to make sure we are able to train a model that is capable of taking arbitrary unseen data and classifying it with a high degree of accuracy.</p>
<p>We will use the KNearestNeighbor classifier which finds a predefined (<span class="math inline"><em>k</em></span>) number training samples and produces a label prediction from those the majority agreement of the <span class="math inline"><em>k</em></span> votes. While the <span class="math inline"><em>k</em></span> does not have to be user-defined as in the case of radius-based neighbor learning, we will stick with a predefined <span class="math inline"><em>K</em></span> of 10. While considered a <em>non-generalizing</em> machine learning technique, it can be very successful in cases where class boundaries are irregularly shaped. You can learn more about the <code>sklearn</code> tools for nearest neighbors here: <a href="https://scikit-learn.org/stable/modules/neighbors.html#neighbors">https://scikit-learn.org/stable/modules/neighbors.html#neighbors</a>.</p>
<p>You will train, test and validate in this part of the assignment.</p>
<ol type="1">
<li>Write the code in your notebook to build the classifier using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"><code>KNeighborsClassifier</code></a>. Here are a few tips:</li>
</ol>
<ul>
<li>make sure you split the class labels correctly (i.e. do not include them in the feature set expected in the <span class="math inline"><em>X</em></span> parameter of the <code>fit()</code> method).</li>
</ul>
<ol start="2" type="1">
<li>Use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score"><code>score</code></a> method to test your model’s accuracy. Your notebook must include an individual assessment of the score, which is the mean accuracy of the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict"><code>predict</code></a> method over the test data.</li>
<li>Please comment on the accuracy of your model. Would you trust it in the wild? Why or Why not? If the accuracy is not what you would think is worthy, please go back and make updates to the <span class="math inline"><em>k</em></span> parameter which you have control over in the previous step. When you have found a <span class="math inline"><em>k</em></span> that is satisfactory, go to the next step (NOTE: this step may not be necessary, if for example, your classifier achieves &gt; 0.80 accuracy).</li>
</ol>
<p>§ Evaluating and reflecting on your model is an important and relevant step to take when building them. Answer the following questions:</p>
<ol type="1">
<li>Now that you have a model and may be fairly happy with it, please score the data on the holdout set. Make sure you have a cell in your notebook that shows the accuracy of the model on the holdout.</li>
<li>Do you think the your model is ready for prime time? Why or why not?</li>
</ol>
<p>§ We spent time early on <em>creating</em> classes for our model. But with the diamonds what we really might like to have is a model that can give us a price, given the input features. While humans still control much of the evaluation and pricing process of the diamond business, machines might still be useful in situations where fast decisions might be made on less expensive diamonds or where margins may be so large that even suboptimal pricing is acceptable.</p>
<p>Using what we learned before, we’re going to build upon the same concepts except this time, we won’t need the labels. In building a <em>regressor</em> instead of predicting discrete class labels, we are going to predict a <em>continuous value</em> or in our case, the one that matters most: <em>price</em>. Like the classifier the regressor will make predictions based on the mean value of the <span class="math inline"><em>k</em></span> neighbors.</p>
<ol type="1">
<li>You will adapt your code above to produce the regressor (it will be very easy, instead of the class label as the input to the <span class="math inline"><em>y</em></span> parameter of <code>fit</code>, use the price, of course making sure you drop it and the label from your <span class="math inline"><em>X</em></span> input parameter.</li>
</ol>
<p>To complete this study the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor"><code>sklearn.neighbors.KNeighborsRegressor</code></a>. Use the same splits as the classifier above.</p>
<ol start="2" type="1">
<li>The <code>predict</code> method works similarly as before except this time it returns an <span class="math inline"><em>R</em><sup>2</sup></span> value of the prediction – recall the closer <span class="math inline"><em>R</em><sup>2</sup></span> is to 1.0, the better the fit. Make sure you do the prediction on the test data. Play with the model a bit if necessary to determine the impact of changes on the score.</li>
<li>Take the validation set and again determine the score. Do you feel the model is ready for prime time? Please be specific on why you feel that way?</li>
<li>Using your model, please take the sample file <a href="./hw2_price_test_sample.csv">hw2_price_test_sample.csv</a> from the course repo and produce prices for each input instance. The output will be a file with the price as a feature (output column in your file). Make sure you name the file <code>price_predictions.csv</code> so I can look at it.</li>
</ol>
