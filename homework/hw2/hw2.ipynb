{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# MCIS6273 Data Mining (Prof. Maull) / Fall 2020 / HW2\n", "\n", "**This assignment is worth up to 10 POINTS to your grade total if you complete it on time.**\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 10 | Monday, November 9 @ Midnight | _up to_ 20 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Perform unsupervised learning with nearest-neighbors classification and regression\n", "\n", "* Perform Bayesian text classification\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hwN`.   Put all of your files in that directory.  Then zip that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hwN_files.zip`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (50%) Perform unsupervised learning with nearest-neighbors classification and regression \n", "\n", "In the last homework we work with the diamonds dataset and learned a lot\n", "about how to understand and visualize some of the features of the data.\n", "\n", "We also learned that maybe the price of diamonds is only partially due to\n", "the rated characteristics of the diamond.  There ar surely more that meets\n", "the eye when pricing diamonds and there are qualitative as well as\n", "quantitative measures which factor into the price of a diamond.\n", "\n", "We're going to continue with this dataset on two routes.  We're\n", "first going to build a classicification model based on the nearest neighbors in\n", "the data.  That is to say, given an arbitrary unseen diamond, we would\n", "like to have a model trained from the actual data which gives us\n", "a class label for that diamond.\n", "\n", "For the sake of the exercise, we're going to choose 5 labels for the diamonds\n", "all based on price.  Instead of arbitrary cuts on those labels, we're\n", "going to use the 2015 US Federal income tax brackets as our guide.\n", "\n", "If you look at the brackets, there are distinct cutoffs which could serve\n", "as bins for our class labels.  We don't care necessarily what the labels\n", "are called, so we will just use letters 'A', 'B', 'C' and so on.\n", "\n", "Once we have obtained the labels (and assigned them), we will then use\n", "the [`sklearn.neighbors.KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n", "to develop a model for classifying the data.  Remember from our\n", "lectures we need to split the data into test, training/validation and a\n", "_holdout_ set.  The training set will be used to train the model,\n", "while the test set will be used to test the model.  The holdout\n", "set will be our \"unseen\" data upon which real classification decisions\n", "will be made.  We can evaluation the fitness of the final model\n", "on the holdout set and (hopefully) gain confidence that the model\n", "will do well in the real world.\n", "\n", "&#167;  Create labels for the data based on the first 5 tax brackets from the 2015 US Federal Income\n", "brackets.  You only need to consider the _Single_ 10%, 15%, 25%, 28% and 33% brackets which ends\n", "at $411,500.  **Do not use the married or head of household brackets**.  The full bracket information\n", "can be found here: [https://www.bankrate.com/finance/taxes/2015-tax-bracket-rates.aspx](https://www.bankrate.com/finance/taxes/2015-tax-bracket-rates.aspx).\n", "\n", "1. For each bracket compute a value $\\varphi$ which is 10% of half the difference between the\n", "   top and bottom of the bracket.\n", "   For example, $$\\varphi_c = \\frac{b_{max} - b_{min}}{2} \\times 0.10$$.\n", "\n", "\n", "   So if the top of a bracket $b_{max} = 5000$ and the bottom of the bracket $b_{min}=2500$, then\n", "   $\\varphi = 125$.  This number will represent the cutoff of the class, so that the range\n", "   for the class extends from the previous class to the current one just calculated.  The classes\n", "   will ultimately look like this $C_1 = [0, \\varphi_{c_1}], C_2 = (\\varphi_{c_1}, \\varphi_{c_2}], \\ldots, C_n =(\\varphi_{c_{n-1}}, \\varphi_{c_n}]$.\n", "\n", "2. Now label the original data from your diamonds data with the labels 'A' ... 'E' where 'A' is the\n", "   first class, 'B', the second and so on.  You will need to create a function that checks\n", "   the class ranges for the price and applies that function  accordingly to produce a new feature `class`.\n", "   You can do this very simply with the [`apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) function.\n", "\n", "3. Store the labeled data (the new DataFrame with the class) into a file for all rows.\n", "\n", "\n", "&#167;  Now that we have the dataset, let's create a training and test set and beging model building.\n", "The easiest way to create your holdout set is to take a random sample of 25% of the\n", "data and use that as the holdout.  You can can take the remaining 75% of the data and\n", "use it for the test/train split.  While there are not steadfast rules for how much data\n", "you should use to train, test and validate with, a good rule of thumb is to train on no less\n", "than 20% of the data, if possible, and validate on between 20-25% of the data.  If you have a large enough dataset\n", "(millions of instances), you may be able to train on 10% of the data.  Of course, your choice of\n", "classifier may also help guide the decision on splitting data.\n", "\n", "1. Create a 25% validation set and use the remaining data to do a 30%/70% test/train split.  We have\n", "   enough instances to create a dataset that should yield good accuracy.  The [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is a great place to start\n", "   and will save you a great deal of time.\n", "\n", "2. Store the data into 3 files `test.csv`, `train.csv` and `validate.csv`.\n", "\n", "\n", "&#167;  Now that we have data that we need, we can perform the classification task we originally wanted.  Recall,\n", "the goal is to make sure we are able to train a model that is capable of taking arbitrary unseen data\n", "and classifying it with a high degree of accuracy.\n", "\n", "We will use the KNearestNeighbor classifier which finds a predefined ($k$) number training\n", "samples and produces a label prediction from those the majority agreement of the $k$ votes.  While the $k$ does not have to be\n", "user-defined as in the case of radius-based neighbor learning, we will stick with a predefined\n", "$K$ of 10.  While considered a _non-generalizing_ machine learning technique, it can be very\n", "successful in cases where class boundaries are irregularly shaped.  You can learn more about\n", "the `sklearn` tools for nearest neighbors here: [https://scikit-learn.org/stable/modules/neighbors.html#neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors).\n", "\n", "You will train, test and validate in this part of the assignment.\n", "\n", "1. Write the code in your notebook to build the classifier using the [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier).  Here\n", "are a few tips:\n", "\n", "- make sure you split the class labels correctly (i.e. do not include them in the feature set expected\n", "  in the $X$ parameter of the `fit()` method).\n", "2. Use the [`score`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score) method to test your model's accuracy.  Your notebook must include\n", "   an individual assessment of the score, which is the mean accuracy of the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) method\n", "   over the test data.\n", "3. Please comment on the accuracy of your model.  Would you trust it in the wild?  Why or Why not? If the\n", "   accuracy is not what you would think is worthy, please go back and make updates to the $k$ parameter\n", "   which you have control over in the previous step.  When you have found a $k$ that is satisfactory,\n", "   go to the next step (NOTE: this step may not be necessary, if for example, your classifier achieves > 0.80\n", "   accuracy).\n", "\n", "\n", "&#167;  Evaluating and reflecting on your model is an important and relevant step to take when building them.\n", "Answer the following questions:\n", "\n", " 1. Now that you have a model and may be fairly happy with it, please score the data on the holdout set.\n", "    Make sure you have a cell in your notebook that shows the accuracy of the model on the holdout.\n", " 2. Do you think the your model is ready for prime time?  Why or why not?\n", "\n", "\n", "&#167;  We spent time early on _creating_ classes for our model.  But with the diamonds what we really\n", "might like to have is a model that can give us a price, given the input features.  While humans\n", "still control much of the evaluation and pricing process of the diamond business, machines\n", "might still be useful in situations where fast decisions might be made on less expensive diamonds\n", "or where margins may be so large that even suboptimal pricing is acceptable.\n", "\n", "Using what we learned before, we're going to build upon the same concepts except this time, we won't\n", "need the labels.  In building a _regressor_ instead of predicting discrete class labels, we are going\n", "to predict a _continuous value_ or in our case, the one that matters most: _price_.  Like the classifier\n", "the regressor will make predictions based on the mean value of the $k$ neighbors.\n", "\n", "1. You will adapt your code above to produce the regressor (it will be very easy, instead of the class\n", "label as the input to the $y$ parameter of `fit`, use the price, of course making sure you drop it\n", "and the label from your $X$ input parameter.\n", "\n", "To complete this study the [`sklearn.neighbors.KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor).  Use\n", "the same splits as the classifier above.\n", "\n", "2. The `predict` method works similarly as before except this time it returns an $R^2$ value\n", "   of the prediction -- recall the closer $R^2$ is to 1.0, the better the fit.  Make\n", "   sure you do the prediction on the test data.  Play with the model a bit if necessary\n", "   to determine the impact of changes on the score.\n", "3. Take the validation set and again determine the score.  Do you feel the model is\n", "   ready for prime time?  Please be specific on why you feel that way?\n", "4. Using your model, please take the sample file [hw2_price_test_sample.csv](./hw2_price_test_sample.csv)\n", "   from the course repo and produce prices for each\n", "   input instance.  The output will be a file with the price as a feature (output column in your\n", "   file).  Make sure you name the file `price_predictions.csv` so I can look at it.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}